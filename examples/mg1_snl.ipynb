{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryankelly/python_projects/sbi/venv/lib/python3.9/site-packages/tqdm-4.64.0-py3.9.egg/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# visualization\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sbi\n",
    "from sbi import utils as utils\n",
    "from sbi import analysis as analysis\n",
    "from sbi.inference import SNLE, prepare_for_sbi, simulate_for_sbi\n",
    "from sbi.inference.base import infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MG1(params, n_obs=50, batch_size=1, random_state=None):\n",
    "    \"\"\"Generate a sequence of samples from the M/G/1 model.\n",
    "\n",
    "    The sequence is a moving average\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    t1 : float, array_like\n",
    "        minimum service time length\n",
    "    t2 : float, array_like\n",
    "        maximum service time length\n",
    "    t3 : float, array_like\n",
    "        Time between arrivals Exp(t3) distributed\n",
    "    n_obs : int, optional\n",
    "    batch_size : int, optional\n",
    "    random_state : RandomState, optional\n",
    "\n",
    "    \"\"\"\n",
    "    if isinstance(params, torch.Tensor):\n",
    "        t1, t2, t3 = float(params[0][0]), float(params[0][1]), float(params[0][2])\n",
    "    else:\n",
    "        t1, t2, t3 = params[0], params[1], params[2]\n",
    "\n",
    "    # if hasattr(t1, 'shape'):  # assumes vector consists of identical values\n",
    "    #     t1, t2, t3 = t1[0], t2[0], t3[0]\n",
    "\n",
    "    random_state = random_state or np.random\n",
    "\n",
    "    # arrival time of customer j after customer j - 1\n",
    "    W = random_state.exponential(1/t3, size=(batch_size, n_obs))  # beta = 1/lmda\n",
    "    # service times\n",
    "    U = random_state.uniform(t1, t2, size=(batch_size, n_obs))\n",
    "\n",
    "    y = np.zeros((batch_size, n_obs))\n",
    "    sum_w = W[:, 0]  # arrival time of jth customer, init first time point\n",
    "    sum_x = np.zeros(batch_size)  # departure time of the prev customer, init 0s\n",
    "\n",
    "    for i in range(n_obs):\n",
    "        y[:, i] = U[:, i].flatten() + np.maximum(np.zeros(batch_size), sum_w - sum_x).flatten()\n",
    "        sum_w += W[:, i]\n",
    "        sum_x += y[:, i-1]\n",
    "\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation_wrapper(params):\n",
    "    x_sim = MG1(params)\n",
    "    sim_sum = torch.as_tensor(x_sim.astype('float32'))\n",
    "    return sim_sum.reshape((-1, 50))  # TODO: magic number 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: ACTUAL PRIOR?\n",
    "prior_min = [0, 0, 0 ]\n",
    "prior_max = [10, 10, 0.5]\n",
    "prior = utils.torchutils.BoxUniform(low=torch.as_tensor(prior_min),\n",
    "                                    high=torch.as_tensor(prior_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference = SNLE(prior=prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running 300 simulations.: 100%|██████████| 300/300 [00:00<00:00, 1062.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Neural network successfully converged after 254 epochs."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tuning bracket width...: 100%|██████████| 50/50 [00:03<00:00, 15.50it/s]\n",
      "Generating samples: 100%|██████████| 10/10 [00:03<00:00,  2.83it/s]\n",
      "Generating samples:  27%|██▋       | 82/300 [00:35<01:33,  2.34it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/ryankelly/python_projects/sbi/examples/mg1_snl.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ryankelly/python_projects/sbi/examples/mg1_snl.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m proposal \u001b[39m=\u001b[39m prior\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ryankelly/python_projects/sbi/examples/mg1_snl.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_rounds):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ryankelly/python_projects/sbi/examples/mg1_snl.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     theta, x \u001b[39m=\u001b[39m simulate_for_sbi(simulation_wrapper, proposal, num_simulations\u001b[39m=\u001b[39;49m\u001b[39m300\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ryankelly/python_projects/sbi/examples/mg1_snl.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     density_estimator \u001b[39m=\u001b[39m inference\u001b[39m.\u001b[39mappend_simulations(theta, x\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ryankelly/python_projects/sbi/examples/mg1_snl.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     )\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ryankelly/python_projects/sbi/examples/mg1_snl.ipynb#W5sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     posterior \u001b[39m=\u001b[39m inference\u001b[39m.\u001b[39mbuild_posterior(density_estimator)\n",
      "File \u001b[0;32m~/python_projects/sbi/venv/lib/python3.9/site-packages/sbi-0.18.0-py3.9.egg/sbi/inference/base.py:493\u001b[0m, in \u001b[0;36msimulate_for_sbi\u001b[0;34m(simulator, proposal, num_simulations, num_workers, simulation_batch_size, show_progress_bar)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msimulate_for_sbi\u001b[39m(\n\u001b[1;32m    459\u001b[0m     simulator: Callable,\n\u001b[1;32m    460\u001b[0m     proposal: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    464\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    465\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Tensor, Tensor]:\n\u001b[1;32m    466\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Returns ($\\theta, x$) pairs obtained from sampling the proposal and simulating.\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \n\u001b[1;32m    468\u001b[0m \u001b[39m    This function performs two steps:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[39m    Returns: Sampled parameters $\\theta$ and simulation-outputs $x$.\u001b[39;00m\n\u001b[1;32m    491\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 493\u001b[0m     theta \u001b[39m=\u001b[39m proposal\u001b[39m.\u001b[39;49msample((num_simulations,))\n\u001b[1;32m    495\u001b[0m     x \u001b[39m=\u001b[39m simulate_in_batches(\n\u001b[1;32m    496\u001b[0m         simulator, theta, simulation_batch_size, num_workers, show_progress_bar\n\u001b[1;32m    497\u001b[0m     )\n\u001b[1;32m    499\u001b[0m     \u001b[39mreturn\u001b[39;00m theta, x\n",
      "File \u001b[0;32m~/python_projects/sbi/venv/lib/python3.9/site-packages/sbi-0.18.0-py3.9.egg/sbi/inference/posteriors/mcmc_posterior.py:274\u001b[0m, in \u001b[0;36mMCMCPosterior.sample\u001b[0;34m(self, sample_shape, x, method, thin, warmup_steps, num_chains, init_strategy, init_strategy_parameters, init_strategy_num_candidates, mcmc_parameters, mcmc_method, sample_with, num_workers, show_progress_bars)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mset_grad_enabled(track_gradients):\n\u001b[1;32m    273\u001b[0m     \u001b[39mif\u001b[39;00m method \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mslice_np\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mslice_np_vectorized\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 274\u001b[0m         transformed_samples \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_slice_np_mcmc(\n\u001b[1;32m    275\u001b[0m             num_samples\u001b[39m=\u001b[39;49mnum_samples,\n\u001b[1;32m    276\u001b[0m             potential_function\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpotential_,\n\u001b[1;32m    277\u001b[0m             initial_params\u001b[39m=\u001b[39;49minitial_params,\n\u001b[1;32m    278\u001b[0m             thin\u001b[39m=\u001b[39;49mthin,  \u001b[39m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    279\u001b[0m             warmup_steps\u001b[39m=\u001b[39;49mwarmup_steps,  \u001b[39m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    280\u001b[0m             vectorized\u001b[39m=\u001b[39;49m(method \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mslice_np_vectorized\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    281\u001b[0m             num_workers\u001b[39m=\u001b[39;49mnum_workers,\n\u001b[1;32m    282\u001b[0m             show_progress_bars\u001b[39m=\u001b[39;49mshow_progress_bars,\n\u001b[1;32m    283\u001b[0m         )\n\u001b[1;32m    284\u001b[0m     \u001b[39melif\u001b[39;00m method \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mhmc\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnuts\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mslice\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    285\u001b[0m         transformed_samples \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pyro_mcmc(\n\u001b[1;32m    286\u001b[0m             num_samples\u001b[39m=\u001b[39mnum_samples,\n\u001b[1;32m    287\u001b[0m             potential_function\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpotential_,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    293\u001b[0m             show_progress_bars\u001b[39m=\u001b[39mshow_progress_bars,\n\u001b[1;32m    294\u001b[0m         )\u001b[39m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/python_projects/sbi/venv/lib/python3.9/site-packages/sbi-0.18.0-py3.9.egg/sbi/inference/posteriors/mcmc_posterior.py:444\u001b[0m, in \u001b[0;36mMCMCPosterior._slice_np_mcmc\u001b[0;34m(self, num_samples, potential_function, initial_params, thin, warmup_steps, vectorized, num_workers, show_progress_bars)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[39m\"\"\"Custom implementation of slice sampling using Numpy.\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \n\u001b[1;32m    426\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[39mReturns: Tensor of shape (num_samples, shape_of_single_theta).\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    442\u001b[0m num_chains, dim_samples \u001b[39m=\u001b[39m initial_params\u001b[39m.\u001b[39mshape\n\u001b[0;32m--> 444\u001b[0m samples \u001b[39m=\u001b[39m slice_np_parallized(\n\u001b[1;32m    445\u001b[0m     potential_function,\n\u001b[1;32m    446\u001b[0m     initial_params,\n\u001b[1;32m    447\u001b[0m     num_samples,\n\u001b[1;32m    448\u001b[0m     thin\u001b[39m=\u001b[39;49mthin,\n\u001b[1;32m    449\u001b[0m     warmup_steps\u001b[39m=\u001b[39;49mwarmup_steps,\n\u001b[1;32m    450\u001b[0m     vectorized\u001b[39m=\u001b[39;49mvectorized,\n\u001b[1;32m    451\u001b[0m     num_workers\u001b[39m=\u001b[39;49mnum_workers,\n\u001b[1;32m    452\u001b[0m     show_progress_bars\u001b[39m=\u001b[39;49mshow_progress_bars,\n\u001b[1;32m    453\u001b[0m )\n\u001b[1;32m    455\u001b[0m \u001b[39m# Save sample as potential next init (if init_strategy == 'latest_sample').\u001b[39;00m\n\u001b[1;32m    456\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mcmc_init_params \u001b[39m=\u001b[39m samples[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :]\u001b[39m.\u001b[39mreshape(num_chains, dim_samples)\n",
      "File \u001b[0;32m~/python_projects/sbi/venv/lib/python3.9/site-packages/sbi-0.18.0-py3.9.egg/sbi/samplers/mcmc/slice_numpy.py:526\u001b[0m, in \u001b[0;36mslice_np_parallized\u001b[0;34m(potential_function, initial_params, num_samples, thin, warmup_steps, vectorized, num_workers, show_progress_bars)\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[39m# Show progress bars over batches.\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[39mwith\u001b[39;00m tqdm_joblib(\n\u001b[1;32m    518\u001b[0m     tqdm(\n\u001b[1;32m    519\u001b[0m         \u001b[39mrange\u001b[39m(num_batches),  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    524\u001b[0m     )\n\u001b[1;32m    525\u001b[0m ):\n\u001b[0;32m--> 526\u001b[0m     all_samples \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49mnum_workers)(\n\u001b[1;32m    527\u001b[0m         delayed(run_fun)(initial_params_batch, seed)\n\u001b[1;32m    528\u001b[0m         \u001b[39mfor\u001b[39;49;00m initial_params_batch, seed \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(initial_params_in_batches, seeds)\n\u001b[1;32m    529\u001b[0m     )\n\u001b[1;32m    530\u001b[0m     all_samples \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mstack(all_samples)\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m    531\u001b[0m     samples \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(all_samples)\n",
      "File \u001b[0;32m~/python_projects/sbi/venv/lib/python3.9/site-packages/joblib-1.1.0-py3.9.egg/joblib/parallel.py:1043\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1035\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1040\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1043\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1044\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m~/python_projects/sbi/venv/lib/python3.9/site-packages/joblib-1.1.0-py3.9.egg/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/python_projects/sbi/venv/lib/python3.9/site-packages/joblib-1.1.0-py3.9.egg/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    780\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/python_projects/sbi/venv/lib/python3.9/site-packages/joblib-1.1.0-py3.9.egg/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/python_projects/sbi/venv/lib/python3.9/site-packages/joblib-1.1.0-py3.9.egg/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/python_projects/sbi/venv/lib/python3.9/site-packages/joblib-1.1.0-py3.9.egg/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/python_projects/sbi/venv/lib/python3.9/site-packages/joblib-1.1.0-py3.9.egg/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/python_projects/sbi/venv/lib/python3.9/site-packages/sbi-0.18.0-py3.9.egg/sbi/samplers/mcmc/slice_numpy.py:481\u001b[0m, in \u001b[0;36mslice_np_parallized.<locals>.run_slice_np\u001b[0;34m(inits, seed)\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[39mif\u001b[39;00m warmup_steps \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    480\u001b[0m     posterior_sampler\u001b[39m.\u001b[39mgen(\u001b[39mint\u001b[39m(warmup_steps))\n\u001b[0;32m--> 481\u001b[0m \u001b[39mreturn\u001b[39;00m posterior_sampler\u001b[39m.\u001b[39;49mgen(ceil(num_samples \u001b[39m/\u001b[39;49m num_chains))\n",
      "File \u001b[0;32m~/python_projects/sbi/venv/lib/python3.9/site-packages/sbi-0.18.0-py3.9.egg/sbi/samplers/mcmc/slice_numpy.py:115\u001b[0m, in \u001b[0;36mSliceSampler.gen\u001b[0;34m(self, n_samples, logger, show_info, rng)\u001b[0m\n\u001b[1;32m    112\u001b[0m     rng\u001b[39m.\u001b[39mshuffle(order)\n\u001b[1;32m    114\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m order:\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx[i], _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sample_from_conditional(i, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx[i], rng)\n\u001b[1;32m    117\u001b[0m samples[n] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    119\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mL \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlp_f(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx)\n",
      "File \u001b[0;32m~/python_projects/sbi/venv/lib/python3.9/site-packages/sbi-0.18.0-py3.9.egg/sbi/samplers/mcmc/slice_numpy.py:178\u001b[0m, in \u001b[0;36mSliceSampler._sample_from_conditional\u001b[0;34m(self, i, cxi, rng)\u001b[0m\n\u001b[1;32m    175\u001b[0m wi \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwidth[i]\n\u001b[1;32m    177\u001b[0m \u001b[39m# sample a slice uniformly\u001b[39;00m\n\u001b[0;32m--> 178\u001b[0m logu \u001b[39m=\u001b[39m Li(cxi) \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39mlog(\u001b[39m1.0\u001b[39m \u001b[39m-\u001b[39m rng\u001b[39m.\u001b[39mrand())\n\u001b[1;32m    180\u001b[0m \u001b[39m# position the bracket randomly around the current sample\u001b[39;00m\n\u001b[1;32m    181\u001b[0m lx \u001b[39m=\u001b[39m cxi \u001b[39m-\u001b[39m wi \u001b[39m*\u001b[39m rng\u001b[39m.\u001b[39mrand()\n",
      "File \u001b[0;32m~/python_projects/sbi/venv/lib/python3.9/site-packages/sbi-0.18.0-py3.9.egg/sbi/samplers/mcmc/slice_numpy.py:174\u001b[0m, in \u001b[0;36mSliceSampler._sample_from_conditional.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwidth \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mChain not initialized.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    173\u001b[0m \u001b[39m# conditional log prob\u001b[39;00m\n\u001b[0;32m--> 174\u001b[0m Li \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m t: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlp_f(np\u001b[39m.\u001b[39;49mconcatenate([\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx[:i], [t], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx[i \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m :]]))\n\u001b[1;32m    175\u001b[0m wi \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwidth[i]\n\u001b[1;32m    177\u001b[0m \u001b[39m# sample a slice uniformly\u001b[39;00m\n",
      "File \u001b[0;32m~/python_projects/sbi/venv/lib/python3.9/site-packages/sbi-0.18.0-py3.9.egg/sbi/utils/potentialutils.py:41\u001b[0m, in \u001b[0;36mtransformed_potential\u001b[0;34m(theta, potential_fn, theta_transform, device, track_gradients)\u001b[0m\n\u001b[1;32m     38\u001b[0m theta \u001b[39m=\u001b[39m theta_transform\u001b[39m.\u001b[39minv(transformed_theta)  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m     39\u001b[0m log_abs_det \u001b[39m=\u001b[39m theta_transform\u001b[39m.\u001b[39mlog_abs_det_jacobian(theta, transformed_theta)\n\u001b[0;32m---> 41\u001b[0m posterior_potential \u001b[39m=\u001b[39m potential_fn(theta, track_gradients\u001b[39m=\u001b[39;49mtrack_gradients)\n\u001b[1;32m     42\u001b[0m posterior_potential_transformed \u001b[39m=\u001b[39m posterior_potential \u001b[39m-\u001b[39m log_abs_det\n\u001b[1;32m     43\u001b[0m \u001b[39mreturn\u001b[39;00m posterior_potential_transformed\n",
      "File \u001b[0;32m~/python_projects/sbi/venv/lib/python3.9/site-packages/sbi-0.18.0-py3.9.egg/sbi/inference/potentials/likelihood_based_potential.py:87\u001b[0m, in \u001b[0;36mLikelihoodBasedPotential.__call__\u001b[0;34m(self, theta, track_gradients)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Returns the potential $\\log(p(x_o|\\theta)p(\\theta))$.\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \n\u001b[1;32m     78\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39m    The potential $\\log(p(x_o|\\theta)p(\\theta))$.\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[39m# Calculate likelihood over trials and in one batch.\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m log_likelihood_trial_sum \u001b[39m=\u001b[39m _log_likelihoods_over_trials(\n\u001b[1;32m     88\u001b[0m     x\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx_o,\n\u001b[1;32m     89\u001b[0m     theta\u001b[39m=\u001b[39;49mtheta\u001b[39m.\u001b[39;49mto(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice),\n\u001b[1;32m     90\u001b[0m     net\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlikelihood_estimator,\n\u001b[1;32m     91\u001b[0m     track_gradients\u001b[39m=\u001b[39;49mtrack_gradients,\n\u001b[1;32m     92\u001b[0m )\n\u001b[1;32m     94\u001b[0m \u001b[39mreturn\u001b[39;00m log_likelihood_trial_sum \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprior\u001b[39m.\u001b[39mlog_prob(theta)\n",
      "File \u001b[0;32m~/python_projects/sbi/venv/lib/python3.9/site-packages/sbi-0.18.0-py3.9.egg/sbi/inference/potentials/likelihood_based_potential.py:135\u001b[0m, in \u001b[0;36m_log_likelihoods_over_trials\u001b[0;34m(x, theta, net, track_gradients)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39m# Calculate likelihood in one batch.\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mset_grad_enabled(track_gradients):\n\u001b[0;32m--> 135\u001b[0m     log_likelihood_trial_batch \u001b[39m=\u001b[39m net\u001b[39m.\u001b[39;49mlog_prob(x_repeated, theta_repeated)\n\u001b[1;32m    136\u001b[0m     \u001b[39m# Reshape to (x-trials x parameters), sum over trial-log likelihoods.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     log_likelihood_trial_sum \u001b[39m=\u001b[39m log_likelihood_trial_batch\u001b[39m.\u001b[39mreshape(\n\u001b[1;32m    138\u001b[0m         x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m    139\u001b[0m     )\u001b[39m.\u001b[39msum(\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/python_projects/sbi/venv/lib/python3.9/site-packages/nflows-0.14-py3.9.egg/nflows/distributions/base.py:40\u001b[0m, in \u001b[0;36mDistribution.log_prob\u001b[0;34m(self, inputs, context)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[39mif\u001b[39;00m inputs\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m context\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n\u001b[1;32m     37\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     38\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mNumber of input items must be equal to number of context items.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     39\u001b[0m         )\n\u001b[0;32m---> 40\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_prob(inputs, context)\n",
      "File \u001b[0;32m~/python_projects/sbi/venv/lib/python3.9/site-packages/nflows-0.14-py3.9.egg/nflows/flows/base.py:39\u001b[0m, in \u001b[0;36mFlow._log_prob\u001b[0;34m(self, inputs, context)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_log_prob\u001b[39m(\u001b[39mself\u001b[39m, inputs, context):\n\u001b[1;32m     38\u001b[0m     embedded_context \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_embedding_net(context)\n\u001b[0;32m---> 39\u001b[0m     noise, logabsdet \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transform(inputs, context\u001b[39m=\u001b[39;49membedded_context)\n\u001b[1;32m     40\u001b[0m     log_prob \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_distribution\u001b[39m.\u001b[39mlog_prob(noise, context\u001b[39m=\u001b[39membedded_context)\n\u001b[1;32m     41\u001b[0m     \u001b[39mreturn\u001b[39;00m log_prob \u001b[39m+\u001b[39m logabsdet\n",
      "File \u001b[0;32m~/python_projects/sbi/venv/lib/python3.9/site-packages/torch-1.12.0-py3.9-macosx-10.9-x86_64.egg/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/python_projects/sbi/venv/lib/python3.9/site-packages/nflows-0.14-py3.9.egg/nflows/transforms/base.py:56\u001b[0m, in \u001b[0;36mCompositeTransform.forward\u001b[0;34m(self, inputs, context)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, inputs, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     55\u001b[0m     funcs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transforms\n\u001b[0;32m---> 56\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cascade(inputs, funcs, context)\n",
      "File \u001b[0;32m~/python_projects/sbi/venv/lib/python3.9/site-packages/nflows-0.14-py3.9.egg/nflows/transforms/base.py:50\u001b[0m, in \u001b[0;36mCompositeTransform._cascade\u001b[0;34m(inputs, funcs, context)\u001b[0m\n\u001b[1;32m     48\u001b[0m total_logabsdet \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mnew_zeros(batch_size)\n\u001b[1;32m     49\u001b[0m \u001b[39mfor\u001b[39;00m func \u001b[39min\u001b[39;00m funcs:\n\u001b[0;32m---> 50\u001b[0m     outputs, logabsdet \u001b[39m=\u001b[39m func(outputs, context)\n\u001b[1;32m     51\u001b[0m     total_logabsdet \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m logabsdet\n\u001b[1;32m     52\u001b[0m \u001b[39mreturn\u001b[39;00m outputs, total_logabsdet\n",
      "File \u001b[0;32m~/python_projects/sbi/venv/lib/python3.9/site-packages/torch-1.12.0-py3.9-macosx-10.9-x86_64.egg/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/python_projects/sbi/venv/lib/python3.9/site-packages/nflows-0.14-py3.9.egg/nflows/transforms/autoregressive.py:39\u001b[0m, in \u001b[0;36mAutoregressiveTransform.forward\u001b[0;34m(self, inputs, context)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, inputs, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     38\u001b[0m     autoregressive_params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mautoregressive_net(inputs, context)\n\u001b[0;32m---> 39\u001b[0m     outputs, logabsdet \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_elementwise_forward(inputs, autoregressive_params)\n\u001b[1;32m     40\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs, logabsdet\n",
      "File \u001b[0;32m~/python_projects/sbi/venv/lib/python3.9/site-packages/nflows-0.14-py3.9.egg/nflows/transforms/autoregressive.py:96\u001b[0m, in \u001b[0;36mMaskedAffineAutoregressiveTransform._elementwise_forward\u001b[0;34m(self, inputs, autoregressive_params)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_elementwise_forward\u001b[39m(\u001b[39mself\u001b[39m, inputs, autoregressive_params):\n\u001b[0;32m---> 96\u001b[0m     unconstrained_scale, shift \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_unconstrained_scale_and_shift(\n\u001b[1;32m     97\u001b[0m         autoregressive_params\n\u001b[1;32m     98\u001b[0m     )\n\u001b[1;32m     99\u001b[0m     \u001b[39m# scale = torch.sigmoid(unconstrained_scale + 2.0) + self._epsilon\u001b[39;00m\n\u001b[1;32m    100\u001b[0m     scale \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39msoftplus(unconstrained_scale) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_epsilon\n",
      "File \u001b[0;32m~/python_projects/sbi/venv/lib/python3.9/site-packages/nflows-0.14-py3.9.egg/nflows/transforms/autoregressive.py:125\u001b[0m, in \u001b[0;36mMaskedAffineAutoregressiveTransform._unconstrained_scale_and_shift\u001b[0;34m(self, autoregressive_params)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_unconstrained_scale_and_shift\u001b[39m(\u001b[39mself\u001b[39m, autoregressive_params):\n\u001b[1;32m    118\u001b[0m     \u001b[39m# split_idx = autoregressive_params.size(1) // 2\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     \u001b[39m# unconstrained_scale = autoregressive_params[..., :split_idx]\u001b[39;00m\n\u001b[1;32m    120\u001b[0m     \u001b[39m# shift = autoregressive_params[..., split_idx:]\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[39m# return unconstrained_scale, shift\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     autoregressive_params \u001b[39m=\u001b[39m autoregressive_params\u001b[39m.\u001b[39mview(\n\u001b[1;32m    123\u001b[0m         \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_dim_multiplier()\n\u001b[1;32m    124\u001b[0m     )\n\u001b[0;32m--> 125\u001b[0m     unconstrained_scale \u001b[39m=\u001b[39m autoregressive_params[\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m, \u001b[39m0\u001b[39;49m]\n\u001b[1;32m    126\u001b[0m     shift \u001b[39m=\u001b[39m autoregressive_params[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39m1\u001b[39m]\n\u001b[1;32m    127\u001b[0m     \u001b[39mreturn\u001b[39;00m unconstrained_scale, shift\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "true_params = [1., 5., 0.2]\n",
    "y = MG1(true_params)\n",
    "\n",
    "num_rounds = 10\n",
    "\n",
    "posteriors = []\n",
    "proposal = prior\n",
    "\n",
    "for _ in range(num_rounds):\n",
    "    theta, x = simulate_for_sbi(simulation_wrapper, proposal, num_simulations=300)\n",
    "    density_estimator = inference.append_simulations(theta, x\n",
    "    ).train()\n",
    "    posterior = inference.build_posterior(density_estimator)\n",
    "    posteriors.append(posterior)\n",
    "    proposal = posterior.set_default_x(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = posterior.sample((5000,),\n",
    "                           x=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = analysis.pairplot(samples,\n",
    "                           limits=[[-1, 1], [-1, 1]],\n",
    "                        #    ticks=[[.5, 1], [.5, 15.]],\n",
    "                           figsize=(5,5),\n",
    "                        #    points=true_params,\n",
    "                           points_offdiag={'markersize': 6},\n",
    "                           points_colors='r');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5fb058963f02392565a913555680c3b76a4a09f49d4749026192587df1ce9307"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
